---
title: "p8105_hw6_mh4588"
author: "Maggie Hsu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse) #Load libraries
library(MASS) #load Mass library for variable selection
#libraries for cross validation
library(modelr)
library(mgcv)
library(SemiPar)

#for NOAA data
remotes::install_github("ropensci/rnoaa")

#Import data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  dplyr::select(name, id, everything())

homicide = read_csv("./homicide-data.csv") #Q2 homicide dataset
birthweight = read_csv("./birthweight.csv") #Q3 birthweight dataset

set.seed(8105) #set seed for randomization 
```
## Question 1
```{r weather}
weather_bootstrap = weather_df |> 
  modelr::bootstrap(n = 5000) |>
  pull(strap) |> 
  nth(1) |> 
  as_tibble()

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
bootstrap_samples = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    sample = map(strap_number, \(i) boot_sample(df = weather_df))
  )


weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(i) lm(tmax ~ tmin, data = weather_df) ),
    results = map(models, broom::glance)
    ) |> 
  #dplyr::select(-strap, -models) |> 
  unnest(results) |> 
  #group_by(id) |> 
  mutate(r2 = pull(var=r.squared,broom::glance(models))), 
b0b1 = log(broom::tidy(lm(tmax ~ tmin, data=weather_df))[1,2] * broom::tidy(lm(tmax ~ tmin, data=weather_df))[2,2])) |>
  
  knitr::kable(digits = 3)
```

## Question 2
```{r homicide}
homicide <- read_csv("./homicide-data.csv") #Import homicide dataset

#Clean data
homicide =  mutate(city_state = paste(city, state, sep=', '), homicide) |> #Create "city,state" variable
  filter(city_state != c("Dallas, TX","Phoenix, AZ","Kansas City, MO")) |> #Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO
   mutate(
     solved = case_when(
      disposition == "Closed by arrest" ~ 1, 
      disposition =="Closed without arrest" ~ 1, 
      disposition == "Open/No arrest" ~ 0)
     ) #Convert solved/unsolved to binary variable

homicide = filter(homicide, victim_race == "White"| victim_race == "Black") |> #Select victim_race to only have observations where victim_race is white or black
  mutate(victim_age = as.numeric(victim_age)) |> #"Unknown" age converted into NAs
 mutate(victim_sex = as.factor(victim_sex)) |>
 mutate(victim_race = as.factor(victim_race))

#Omit data entry error "Tulsa-AL"
which(homicide == "Tul-000769", arr.ind=TRUE) #find row number
homicide <- homicide[-c(38414),]
```

```{r baltimore}
baltimore <- filter(homicide, city=="Baltimore") #Create a subset of the dataset homicide for just Baltimore observations.

baltimore_glm <- glm(solved~victim_age+victim_sex+victim_race, data=baltimore, family = binomial()) #Set up regression model

#Interpret results of regression model
baltimore_glm |>
  broom::tidy() |>
  mutate(OR = exp(estimate), 
         conf_lower = confint(baltimore_glm)[,1], #Confidence interval bounds
         conf_upper = confint(baltimore_glm)[,2]) |>
  filter(term == "victim_sexMale") |> #filter to adjusted odds ratio based on sex
  knitr::kable(digits = 3) 
```
```{r cities glm function}
#Define regression function 
city_reg = function(city) {
  city_data =  filter(homicide, city_state == city)
  reg = lm(solved~victim_age+victim_sex+victim_race, data=city_data)
  
  reg |>
  broom::tidy() |>
  mutate(OR = exp(estimate), 
         conf_lower = confint(reg)[,1],
         conf_upper = confint(reg)[,2]) |>
  filter(term == "victim_sexMale") |>
  knitr::kable(digits = 3) 
}

```

```{r cities glm iteration}
homicide_cities = distinct(homicide["city_state"])
homicide_cities =  as.matrix(unlist(homicide_cities)) #list of cities to iterate over
output = vector("list", length = length(homicide_cities)) #output list

purrr::map(homicide_cities, city_reg)
```
## Question 3

```{r bwt design}
#Proposed design model
#Variable selection using stepwise criteria and AIC/BIC criterion
birthw_full <- lm(bwt~.,data=birthweight)
birthw_stepwise <- stepAIC(birthw_full, direction = "both", trace = FALSE, k=2)
birthw_stepwise_bic <- stepAIC(birthw_full, direction = "both", trace = FALSE, k=log(4342))

#model selection
birthw_aic <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + menarche + mheight + momage + mrace + parity + 
    ppwt + smoken, data = birthweight)
summary(birthw_aic)

birthw_bic <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mrace + ppwt + smoken, data = birthweight)
summary(birthw_bic)

```
I used the AIC (Akaike Info Criterion - compares model fit based on likelihood) and BIC (Bayesian Info Criterion - based on posterior probability) criteria to select variables from the full model based on the lowest AIC or BIC value. Since the BIC-minimized model has a similar R-squared but less variables than the AIC-minimized model (less overfitting), I would go with the BIC model for this problem.

```{r fitted residual}
birthweight = add_predictions(birthweight, birthw_bic) #add fitted values
birthweight = add_residuals(birthweight, birthw_bic) #add residual values

#fitted vs. residual plot
ggplot(data=birthweight)+aes(x=pred, y=resid, color=pred, alpha=0.5)+geom_point() + labs(title="Fitted vs. Residual Values")+xlab("Fitted Values")+ylab("Residual Values")
```
```{r birthweight}
#Model with birth length and gestational age
birthw_lengthage <- lm(bwt~blength+gaweeks, data=birthweight)
summary(birthw_lengthage)
#Model with head circumference, length, sex, and interactions
birthw_interactions <- lm(bwt~bhead+blength+babysex+bhead*blength+blength*babysex+bhead*babysex+bhead*babysex*blength, data=birthweight)
summary(birthw_interactions)
```

```{r model comparison}
#Cross validation
cross_valid = #Create training and testing datasets
  crossv_mc(birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
    )

#Compare models
cross_valid = 
  cross_valid |> 
  mutate(
    lm_bic  = map(
      train, \(df) lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mrace + ppwt + smoken, data = df)
    ),
    lm_lengthage  = map(train, \(df) lm(bwt~blength+gaweeks, data = df)),
    lm_interact  = map(
      train, \(df) lm(bwt~bhead+blength+babysex+bhead*blength+blength*babysex+bhead*babysex+bhead*babysex*blength, data = df)
      )
    ) |> 
  mutate( #Compare RMSE values between models
    rmse_bic = map2_dbl(lm_bic, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_lengthage = map2_dbl(
      lm_lengthage, test, \(mod, df) rmse(model = mod, data = df)
      ),
    rmse_interact = map2_dbl(
      lm_interact, test, \(mod, df) rmse(model = mod, data = df))
    )
```

```{r cv plots}
cross_valid |> #compare RMSE values by model
  dplyr::select(c("rmse_bic","rmse_lengthage","rmse_interact")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse, fill=model)) + geom_violin()+labs(title="Comparison of RMSE by Regression Model")
```
Based on the violin plots here, the length-age regression model has the highest cross-validated RMSE while the regression model with interactions generally has a somewhat higher RMSE than my BIC-criteria model, which generally has the lowest RMSE as shown here. 

Additionally, my proposed model has a higher R-squared and adjusted R-squared than the two previous models birthw_lengthage and birthw_interactions which means that out of these models, the proposed model explains the most out of variation in birth weight.
